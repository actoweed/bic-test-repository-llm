# üöÄ FastAPI + LLM Benchmark (Level 2)

–¢–µ—Å—Ç–æ–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ: —Å–µ—Ä–≤–µ—Ä –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM —á–µ—Ä–µ–∑ [OpenRouter](https://openrouter.ai/), 
—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ–º.

---

## üìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ–µ–∫—Ç–∞

fastapi-llm-benchmark/
‚îú‚îÄ‚îÄ main.py # FastAPI —Å–µ—Ä–≤–µ—Ä
‚îú‚îÄ‚îÄ requirements.txt # –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
‚îú‚îÄ‚îÄ .env.example # –ø—Ä–∏–º–µ—Ä env-—Ñ–∞–π–ª–∞ (API-–∫–ª—é—á)
‚îú‚îÄ‚îÄ prompts.txt # –ø—Ä–∏–º–µ—Ä –ø—Ä–æ–º–ø—Ç–æ–≤ –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–∞
‚îú‚îÄ‚îÄ run_tests.py # –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ–≥–æ–Ω —Ç–µ—Å—Ç–æ–≤ (5 generate + 5 benchmark)
‚îú‚îÄ‚îÄ Dockerfile # (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∏–∑–∞—Ü–∏—è
‚îú‚îÄ‚îÄ docker-compose.yml # (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –∑–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ docker-compose
‚îî‚îÄ‚îÄ README.md # —ç—Ç–æ—Ç —Ñ–∞–π–ª

yaml


---

## ‚öôÔ∏è –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∏ –∑–∞–ø—É—Å–∫ (–ª–æ–∫–∞–ª—å–Ω–æ)

1. **–°–∫–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–µ–∫—Ç –∏ –ø–µ—Ä–µ–π—Ç–∏ –≤ –ø–∞–ø–∫—É**
   ```bash
   git clone <repo-url> fastapi-llm-benchmark
   cd fastapi-llm-benchmark
–°–æ–∑–¥–∞—Ç—å .env

bash

cp .env.example .env
–∏ –≤—Å—Ç–∞–≤–∏—Ç—å —Å–≤–æ–π –∫–ª—é—á OpenRouter:

ini

OPENROUTER_API_KEY=–≤–∞—à_–∫–ª—é—á
–°–æ–∑–¥–∞—Ç—å –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–µ –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

bash
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows

pip install -r requirements.txt
–ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–µ—Ä

bash

uvicorn main:app --host 127.0.0.1 --port 8000
üî• –ü—Ä–∏–º–µ—Ä—ã –∑–∞–ø—Ä–æ—Å–æ–≤ (cURL)
1. –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
bash

curl -s "http://127.0.0.1:8000/models"
2. –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
bash

curl -sS -X POST "http://127.0.0.1:8000/generate" \
  -H "Content-Type: application/json" \
  -d '{"prompt":"–ù–∞–ø–∏—à–∏ —Å—Ç–∏—Ö –ø—Ä–æ Python","model":"deepseek/deepseek-chat-v3.1:free","max_tokens":100}'
3. Benchmark (multipart/form-data)
bash

curl -sS -X POST "http://127.0.0.1:8000/benchmark" \
  -F "prompt_file=@prompts.txt;type=text/plain" \
  -F "model=deepseek/deepseek-chat-v3.1:free" \
  -F "runs=3"
üìä –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ç–µ—Å—Ç—ã
–ü—Ä–æ–µ–∫—Ç –≤–∫–ª—é—á–∞–µ—Ç —Å–∫—Ä–∏–ø—Ç run_tests.py, –∫–æ—Ç–æ—Ä—ã–π –≤—ã–ø–æ–ª–Ω—è–µ—Ç:

5 —Ç–µ—Å—Ç–æ–≤ –Ω–∞ /generate (—Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏, —Ä–∞–∑–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã);

5 —Ç–µ—Å—Ç–æ–≤ –Ω–∞ /benchmark (—Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–æ–Ω–æ–≤).

–ó–∞–ø—É—Å–∫
–í –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ (—Å–µ—Ä–≤–µ—Ä —É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∑–∞–ø—É—â–µ–Ω):

bash

python run_tests.py
–†–µ–∑—É–ª—å—Ç–∞—Ç—ã
–≤—Å–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ –ø–∞–ø–∫—É artifacts/;

—Ç–∞–º –±—É–¥—É—Ç:

test_results.csv ‚Äî —Å–≤–æ–¥–∫–∞ –ø–æ 10 —Ç–µ—Å—Ç–∞–º;

–∫–æ–ø–∏–∏ benchmark_results.csv –∏ server_logs.txt (–µ—Å–ª–∏ –æ–Ω–∏ –µ—Å—Ç—å –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ).

üê≥ –ó–∞–ø—É—Å–∫ –≤ Docker (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
–°–æ–±—Ä–∞—Ç—å –æ–±—Ä–∞–∑

bash

docker build -t llm-benchmark .
–ó–∞–ø—É—Å–∫ —á–µ—Ä–µ–∑ docker-compose

bash

docker-compose up --build
–°–µ—Ä–≤–µ—Ä –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –Ω–∞ http://127.0.0.1:8000.

üìÇ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç—ã
server_logs.txt ‚Äî –æ—à–∏–±–∫–∏ —Å —Ä–æ—Ç–∞—Ü–∏–µ–π.

benchmark_results.csv ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –±–µ–Ω—á–º–∞—Ä–∫–∞.

artifacts/ ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–≤—Ç–æ—Ç–µ—Å—Ç–æ–≤.

‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ latency
/generate
bash

curl -o /dev/null -sS -w "time_total=%{time_total}\n" \
  -X POST "http://127.0.0.1:8000/generate" \
  -H "Content-Type: application/json" \
  -d '{"prompt":"–°–∫–∞–∂–∏ –ø—Ä–∏–≤–µ—Ç","model":"deepseek/deepseek-chat-v3.1:free"}'
/benchmark
bash

curl -o /dev/null -sS -w "time_total=%{time_total}\n" \
  -X POST "http://127.0.0.1:8000/benchmark" \
  -F "prompt_file=@prompts.txt;type=text/plain" \
  -F "model=deepseek/deepseek-chat-v3.1:free" \
  -F "runs=3"